{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "635cf04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d2a3f391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_spam = pd.read_csv('SMSSpamCollection', sep='\\t', header=None, names=['Label', 'SMS'])\n",
    "print(sms_spam.shape)\n",
    "sms_spam.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961cc99c",
   "metadata": {},
   "source": [
    "Here, we have 5572 SMS, each labelled 'ham' (non spam) or 'spam'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d194ede9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4458, 2)\n",
      "(1114, 2)\n"
     ]
    }
   ],
   "source": [
    "# Let's split the dataset into training set and test set, but first, let's randomize them\n",
    "data_randomize = sms_spam.sample(frac=1, random_state=1)\n",
    "\n",
    "# Index for split\n",
    "training_set_index = round(len(data_randomize) * 0.8)\n",
    "\n",
    "training_set = data_randomize[:training_set_index].reset_index(drop=True)\n",
    "testing_set = data_randomize[training_set_index:].reset_index(drop=True)\n",
    "\n",
    "# reset index adds ano\n",
    "\n",
    "print(training_set.shape)\n",
    "print(testing_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "85bae450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Label                                                SMS\n",
      "0   ham                       Yep, by the pretty sculpture\n",
      "1   ham      Yes, princess. Are you going to make me moan?\n",
      "2   ham                         Welp apparently he retired\n",
      "3   ham                                            Havent.\n",
      "4   ham  I forgot 2 ask ü all smth.. There's a card on ...\n",
      "  Label                                                SMS\n",
      "0   ham          Later i guess. I needa do mcat study too.\n",
      "1   ham             But i haf enuff space got like 4 mb...\n",
      "2  spam  Had your mobile 10 mths? Update to latest Oran...\n",
      "3   ham  All sounds good. Fingers . Makes it difficult ...\n",
      "4   ham  All done, all handed in. Don't know if mega sh...\n"
     ]
    }
   ],
   "source": [
    "print(training_set.head())\n",
    "print(testing_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf83d86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.86541\n",
       "spam    0.13459\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45071a3",
   "metadata": {},
   "source": [
    "Here we see that about 87% of messages in training set are ham and the remaining 13% are spam\n",
    "\n",
    "# Naive Bayes\n",
    "\n",
    "\n",
    "$$\n",
    "P(spam | w_1, w_2, ... , w_n) \\propto P(spam) \\prod_{i=1}^{n} P(w_i | spam)\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(ham | w_1, w_2, ... , w_n) \\propto P(ham) \\prod_{i=1}^{n} P(w_i | ham)\n",
    "$$\n",
    "\n",
    "If $P(spam | w_1, w_2, ... , w_n)$ is greater than $P(ham | w_1, w_2, ... , w_n)$ then the message is spam \\\\\n",
    "\n",
    "\n",
    "Each term in the product is calculated as follows:\n",
    "\n",
    "$$\n",
    "P(w_i | spam) = \\frac{N_{w_i | spam} + \\alpha}{N_{spam} + \\alpha \\cdot N_{vocabulary}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(w_i | ham) = \\frac{N_{w_i | ham} + \\alpha}{N_{ham} + \\alpha \\cdot N_{vocabulary}}\n",
    "$$\n",
    "\n",
    "\n",
    "$N_{w_i | spam} =$ the number of times the word w_i appears in spam messages\n",
    "\n",
    "$N_{w_i | ham} =$ the number of times the word w_i appears in ham messages  \n",
    "\n",
    "$N_{spam} =$ total number of spam words\n",
    "\n",
    "$N_{ham} =$ total number of ham words\n",
    "\n",
    "$N_{vocabulary} =$ total number of words in the vocabulary\n",
    "\n",
    "$\\alpha = 1$, the laplace smoothing parameter\n",
    "\n",
    "We need to reformat and clean the data for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "404cc6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                            SMS\n",
       "0   ham                   yep  by the pretty sculpture\n",
       "1   ham  yes  princess  are you going to make me moan \n",
       "2   ham                     welp apparently he retired"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets remove punctuation and convert all words to lowercase\n",
    "training_set['SMS'] = training_set['SMS'].str.replace(\n",
    "    '\\W', ' ', regex=True) #using regex to remove a non word character (\\W is a non-word character)\n",
    "training_set['SMS'] = training_set['SMS'].str.lower()\n",
    "training_set.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "883afec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set['SMS'] = training_set['SMS'].str.split() #split the string by space to a list\n",
    "\n",
    "vocabulary = []\n",
    "for sms in training_set['SMS']:\n",
    "    for word in sms:\n",
    "        vocabulary.append(word) #add every word to vocabulary\n",
    "\n",
    "vocabulary = list(set(vocabulary)) #remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0569e02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7783\n"
     ]
    }
   ],
   "source": [
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32fb2c1",
   "metadata": {},
   "source": [
    "There are 7783 unique words in our vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "765e86ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(training_set['SMS']) for unique_word in vocabulary}\n",
    "\n",
    "\n",
    "for index, sms in enumerate(training_set['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8509cf48",
   "metadata": {},
   "source": [
    "Here, `word_counts_per_sms` is a dictionary, in which the keys are each unique word in the dictionary and the value of each key is a list of length equal to size of training set. $i^{th}$ item of that list is the number of occurence of that word in the $i^{th}$ SMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "26686b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incident</th>\n",
       "      <th>shd</th>\n",
       "      <th>den</th>\n",
       "      <th>voucher</th>\n",
       "      <th>pattern</th>\n",
       "      <th>steps</th>\n",
       "      <th>wkend</th>\n",
       "      <th>wonderful</th>\n",
       "      <th>slow</th>\n",
       "      <th>kavalan</th>\n",
       "      <th>...</th>\n",
       "      <th>sticky</th>\n",
       "      <th>countin</th>\n",
       "      <th>door</th>\n",
       "      <th>coccooning</th>\n",
       "      <th>thy</th>\n",
       "      <th>8027</th>\n",
       "      <th>3650</th>\n",
       "      <th>je</th>\n",
       "      <th>intend</th>\n",
       "      <th>landlineonly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   incident  shd  den  voucher  pattern  steps  wkend  wonderful  slow  \\\n",
       "0         0    0    0        0        0      0      0          0     0   \n",
       "1         0    0    0        0        0      0      0          0     0   \n",
       "2         0    0    0        0        0      0      0          0     0   \n",
       "3         0    0    0        0        0      0      0          0     0   \n",
       "4         0    0    0        0        0      0      0          0     0   \n",
       "\n",
       "   kavalan  ...  sticky  countin  door  coccooning  thy  8027  3650  je  \\\n",
       "0        0  ...       0        0     0           0    0     0     0   0   \n",
       "1        0  ...       0        0     0           0    0     0     0   0   \n",
       "2        0  ...       0        0     0           0    0     0     0   0   \n",
       "3        0  ...       0        0     0           0    0     0     0   0   \n",
       "4        0  ...       0        0     0           0    0     0     0   0   \n",
       "\n",
       "   intend  landlineonly  \n",
       "0       0             0  \n",
       "1       0             0  \n",
       "2       0             0  \n",
       "3       0             0  \n",
       "4       0             0  \n",
       "\n",
       "[5 rows x 7783 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = pd.DataFrame(word_counts_per_sms)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b474e5",
   "metadata": {},
   "source": [
    "Let's concatenate this dataframe to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a85ed969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>incident</th>\n",
       "      <th>shd</th>\n",
       "      <th>den</th>\n",
       "      <th>voucher</th>\n",
       "      <th>pattern</th>\n",
       "      <th>steps</th>\n",
       "      <th>wkend</th>\n",
       "      <th>wonderful</th>\n",
       "      <th>...</th>\n",
       "      <th>sticky</th>\n",
       "      <th>countin</th>\n",
       "      <th>door</th>\n",
       "      <th>coccooning</th>\n",
       "      <th>thy</th>\n",
       "      <th>8027</th>\n",
       "      <th>3650</th>\n",
       "      <th>je</th>\n",
       "      <th>intend</th>\n",
       "      <th>landlineonly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  incident  shd  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]         0    0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...         0    0   \n",
       "2   ham                    [welp, apparently, he, retired]         0    0   \n",
       "3   ham                                           [havent]         0    0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...         0    0   \n",
       "\n",
       "   den  voucher  pattern  steps  wkend  wonderful  ...  sticky  countin  door  \\\n",
       "0    0        0        0      0      0          0  ...       0        0     0   \n",
       "1    0        0        0      0      0          0  ...       0        0     0   \n",
       "2    0        0        0      0      0          0  ...       0        0     0   \n",
       "3    0        0        0      0      0          0  ...       0        0     0   \n",
       "4    0        0        0      0      0          0  ...       0        0     0   \n",
       "\n",
       "   coccooning  thy  8027  3650  je  intend  landlineonly  \n",
       "0           0    0     0     0   0       0             0  \n",
       "1           0    0     0     0   0       0             0  \n",
       "2           0    0     0     0   0       0             0  \n",
       "3           0    0     0     0   0       0             0  \n",
       "4           0    0     0     0   0       0             0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_clean = pd.concat([training_set, word_counts], axis=1)\n",
    "training_set_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f785a2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolating the ham and spam messages first\n",
    "spam_messages = training_set_clean[training_set_clean['Label'] == 'spam']\n",
    "ham_messages = training_set_clean[training_set_clean['Label'] == 'ham']\n",
    "\n",
    "# P(spam) and P(ham)\n",
    "p_spam = len(spam_messages) / len(training_set_clean)\n",
    "p_ham = len(ham_messages) / len(training_set_clean)\n",
    "\n",
    "# N_spam: total number of words in spam messages\n",
    "n_words_per_spam_message = spam_messages['SMS'].apply(len)\n",
    "n_spam = n_words_per_spam_message.sum()\n",
    "\n",
    "n_words_per_ham_message = ham_messages['SMS'].apply(len)\n",
    "n_ham = n_words_per_ham_message.sum()\n",
    "\n",
    "# N_vocabulary\n",
    "n_vocabulary = len(vocabulary)\n",
    "\n",
    "#Laplace smoothing\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe964bc",
   "metadata": {},
   "source": [
    "Now, let's calculate parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c6b9c0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "parameters_spam = {unique_word: 0 for unique_word in vocabulary}\n",
    "parameters_ham = {unique_word: 0 for unique_word in vocabulary}\n",
    "\n",
    "# Calculate the parameters\n",
    "for word in vocabulary:\n",
    "    n_word_given_spam = spam_messages[word].sum()\n",
    "    p_word_given_spam = (n_word_given_spam + alpha) / (n_spam + alpha * n_vocabulary)\n",
    "    parameters_spam[word] = p_word_given_spam\n",
    "    \n",
    "    n_word_given_ham = ham_messages[word].sum()\n",
    "    p_word_given_ham = (n_word_given_ham + alpha) / (n_ham + alpha * n_vocabulary)\n",
    "    parameters_ham[word] = p_word_given_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8b725d",
   "metadata": {},
   "source": [
    "Our model is complete. Next, we will build a classify function, and we will test the accuracy of our model using  `testing_set`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "026650a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify (message):\n",
    "    \"\"\"message: a string\"\"\"\n",
    "    message = re.sub('\\W', ' ', message) #remove non word characters\n",
    "    message = message.lower().split() # lowercase and make list by splitting using spaces\n",
    "    \n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham #prior probabilities\n",
    "    \n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "        \n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word]\n",
    "    \n",
    "    print(\"P (Spam | message): \", p_spam_given_message)\n",
    "    print(\"P (Ham | message): \", p_ham_given_message)\n",
    "    \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print(\"Label: Ham\")\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print(\"Label: Spam\")\n",
    "    else:\n",
    "        print(\"Have a human classify this!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "26ce8def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P (Spam | message):  1.3481290211300841e-25\n",
      "P (Ham | message):  1.9368049028589875e-27\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6e3f6f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P (Spam | message):  2.4372375665888117e-25\n",
      "P (Ham | message):  3.687530435009238e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classify(\"Sounds good, Tom, then see u there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aba4875",
   "metadata": {},
   "source": [
    "There you go! it classified well for these two messages. Now we will feed the algorithm the entire testing set to see its accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "baa6bc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "    \"\"\"message: a string\"\"\"\n",
    "    \n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower().split()\n",
    "    \n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word]\n",
    "    \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ae1bf818",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham          Later i guess. I needa do mcat study too.       ham\n",
       "1   ham             But i haf enuff space got like 4 mb...       ham\n",
       "2  spam  Had your mobile 10 mths? Update to latest Oran...      spam\n",
       "3   ham  All sounds good. Fingers . Makes it difficult ...       ham\n",
       "4   ham  All done, all handed in. Don't know if mega sh...       ham"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_set['predicted'] = testing_set['SMS'].apply(classify_test_set)\n",
    "testing_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6e570004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:  1100\n",
      "Incorrect:  14\n",
      "Accuracy:  98.74326750448833 %\n"
     ]
    }
   ],
   "source": [
    "# calculating accuracy\n",
    "correct = 0\n",
    "total = testing_set.shape[0]\n",
    "\n",
    "for row in testing_set.iterrows():\n",
    "    row = row[1]\n",
    "    if row['Label'] == row['predicted']:\n",
    "        correct += 1\n",
    "\n",
    "print(\"Correct: \", correct)\n",
    "print(\"Incorrect: \", total - correct)\n",
    "print(\"Accuracy: \", (correct*100 / total), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a10daa",
   "metadata": {},
   "source": [
    "That's about 99% accurate! Hurray!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
