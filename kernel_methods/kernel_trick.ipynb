{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yUDRAJaMTR0C"
   },
   "source": [
    "# LMS with Kernel Trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NxnYGPEdTR0F"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708
    },
    "id": "OhTYOgYwTR0I",
    "outputId": "d917528a-149a-4cf4-f2d7-54f6ddb24db5"
   },
   "outputs": [],
   "source": [
    "file = pd.read_csv(\"california_housing_train.csv\")\n",
    "file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3aN06mvTR0J"
   },
   "source": [
    "As you can see, there are 12 different input features, but we will remove some, and use only a few others. Also, my pc can't handle this load :P so I'm reducing the dataset size. I'll use only $10k$ data sets. Also, we'll split that into training set and testing set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-kNfAkhTR0K"
   },
   "outputs": [],
   "source": [
    "#selecting only the required columns\n",
    "# useful_index = [3, 4, 5, 6, 7, 8, 10]\n",
    "# file = file.iloc[:, useful_index]\n",
    "\n",
    "# getting training set and test set\n",
    "file = file.sample(frac=1, random_state=1)\n",
    "\n",
    "# useable data size\n",
    "usable_dataset_size = 2000\n",
    "\n",
    "# get rid of unnecessary data\n",
    "file = file[:usable_dataset_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FjFFL_8TR0L"
   },
   "source": [
    "## Objective: To predict apparent temperature from other features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S3TAf9hTTR0L"
   },
   "source": [
    "### 1. Arrange the data in appropriate format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B6NglZnITR0M"
   },
   "outputs": [],
   "source": [
    "# Select the columns\n",
    "X = file.iloc[:, :-1]\n",
    "output_index = [-1]\n",
    "Y = file.iloc[:, output_index]\n",
    "\n",
    "# Convert to numpy into suitable format\n",
    "X = X.to_numpy()\n",
    "n = X.shape[0]\n",
    "d = X.shape[1]\n",
    "\n",
    "Y = Y.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0N5ZtXSEalcE"
   },
   "source": [
    "### 3. Construct the training and prediction function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dUIkwADYTR0G"
   },
   "source": [
    "The following function calculates the kernel $\\langle \\phi\\left(x\\right), \\phi\\left(y\\right) \\rangle$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D5hBG2TITR0H"
   },
   "outputs": [],
   "source": [
    "def make_kernel(X, degree=1):\n",
    "    \"\"\"K is the matrix of dot product. This applies kernel function to the matrix\"\"\"\n",
    "    K = np.matmul(X, X.T)\n",
    "    result = np.zeros(K.shape)\n",
    "    for i in range(0, degree+1):\n",
    "        result += np.power(K, i)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function trains the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zCEfPfRUYhp-"
   },
   "outputs": [],
   "source": [
    "def lms_with_kt(X, Y, alpha, degree = 1, num_iters = 1000):\n",
    "    \"\"\"X: nxd vector, Y: nx1 vector, beta: nx1 zero vector, alpha: number, degree: number\"\"\"\n",
    "    # normalize x\n",
    "    x_min = X.min(axis = 0, keepdims=True)\n",
    "    x_max = X.max(axis = 0, keepdims=True)\n",
    "    X = (X - x_min) / (x_max - x_min)\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    # add the column of 1 in the front\n",
    "    # X = np.hstack((np.ones((n, 1)), X))\n",
    "    \n",
    "    # make K_matrix (kernel matrix)\n",
    "    K = make_kernel(X, degree)\n",
    "    \n",
    "    # initialize beta\n",
    "    beta = np.zeros((n, 1))\n",
    "\n",
    "    # update beta\n",
    "    for i in range(num_iters):\n",
    "        beta += alpha * (Y - np.matmul(K, beta))\n",
    "    print(beta)\n",
    "        \n",
    "    def predict(x):\n",
    "        \"\"\"x: 1xd matrix\"\"\"\n",
    "        x_norm = (x - x_min) / (x_max - x_min)\n",
    "        n_predict = x_norm.shape[0]\n",
    "        # x_norm = np.hstack((np.ones((n_predict, 1)), x_norm))\n",
    "        K_for_prediction = np.matmul(X, x_norm.T)\n",
    "        K_for_prediction = kernel_matrix(K_for_prediction, degree)\n",
    "        return np.dot(beta.T, K_for_prediction)\n",
    "\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CiKBdBJgdrwZ"
   },
   "source": [
    "### 4. Train the data and predict the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eL3Sh1IPd1Sy"
   },
   "source": [
    "#### 4.1 Format the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F10wnnhod6ey"
   },
   "outputs": [],
   "source": [
    "# # separate inputs and outputs\n",
    "# test_set_inputs = test_set.iloc[:, input_index]\n",
    "# test_set_outputs = test_set.iloc[:, output_index]\n",
    "\n",
    "# # Convert to numpy\n",
    "# test_set_inputs = test_set_inputs.to_numpy()\n",
    "# test_set_outputs = test_set_outputs.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0ZwxJ-0erzl",
    "outputId": "9990b67e-8866-4688-e6f1-2a36d231235e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictor = lms_with_kt(X, Y, 0.01, 3, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = predictor(test_set_inputs)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "kernel_trick.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}